## 椋木さんのA study on linear algebra operations using extended precision floating-point arithmetic on GPUs
- Utilizing the quadruple-precision floating-point arithmetic operation for the Krylov SubspaceMethods
- Extended-Precision Floating-Point Numbers for GPU Computaion[26]
- Scalar Fused Multiply-Add Instructions Produce Floating-Point Matrix Arithmetic Provably Accurate to the Penultimate Digit
- A Control Method of Errors in Long-Term Integration
- Fast Implementation of DGEMM on Fermi GPU
- An Improved MAGMA GEMM for Fermi GPUs
- A Fast GEMM Implementation On the Cypress GPU
- A Fast Implementation of Matrix-matrix Product in Double-double Precision on NVIDIA C2050 and Application to Semidefinite Programming
- XBLAS – Extra Precise Basic Linear Algebra Subroutines
- The International Exascale Software Project: a Call To Cooperative Action By the Global High-Performance Community
- Efficient Sparse Matrix-Vector Multiplication on CUDA
- Optimizing Sparse Matrix Vector Multiplication Using Cache Blocking Method on Fermi GPU
- [Optimization of Sparse Matrix-Vector Multiplication with Variant CSR on GPUs](#optimization-techniques-for-sparse-matrix–vector-multiplication-on-gpus)
- Accelerating Sparse Matrix Vector Multiplication in Iterative Methods Using GPU
- Optimization of Sparse Matrix-Vector Multiplication by Auto Selecting Storage Schemes on GPU
- Optimizing Sparse Matrix-Vector Multiplication on GPUs, IBM Research Report
- Auto-Tuning CUDA Parameters for Sparse Matrix-Vector Multiplication on GPUs
- Generating Optimal CUDA Sparse Matrix Vector Product Implementations for Evolving GPU Hardware[51]
- Efficient sparse matrix-vector multiplication on cache-based GPUs
- Automatic Tuning of Sparse Matrix-Vector Multiplication for CRS format on GPUs
- Efficient sparse matrix-vector multiplication on cache-based GPUs
- Automatic Tuning of Sparse Matrix-Vector Multiplication for CRS format on GPUs
- A Memory-Bound Application on the GPU Stuck Between a Rock and a Hard Place
- Templates for the Solution of Linear Systems: Building Blocks for Iterative methods, 2nd Edition
- ccelerating scientific computations with mixed precision algorithms
- Implementation of Fast Quad Precision Operation and Acceleration with SSE2 for Iterative Solver Library
- Development of a Stokes flow solver robust to large viscosity jumps using a Schur complement approach with mixed precision arithmetic
- Solving finite difference linear systems on GPUs: CUDA based Parallel Explicit Preconditioned Biconjugate Conjugate Gradient type Methods[#]
- Incomplete-LU and Cholesky Preconditioned Iterative Methods Using CUSPARSE and CUBLAS
- Fast Quadruple Precision Arithmetic Library on Parallel Computer SR11000/J2
- Autotuning GEMM Kernels for the Fermi GPU[70]

## Extended-Precision Floating-Point Numbers for GPU Computaion[26] 
- High-precision floating-point arithmetic in scientific computation
- Performance and accuracy of hardware-oriented native-, emulated- and mixed-precision solvers in FEM simulations
- A floating point technique for extending the available precision
- A FORTRAN multiple-precision arithmetic package
- A Fortran package for floating-point multiple-precision arithmetic
- A Fortran 90-based multiprecision system
- Adaptive precision floating-point arithmetic and fast robust geometric predicates
- A Fortran-90 double-double precision library
- Algorithms for quad- double precision floating point arithmetic
- Quad-double arithmetic: algorithms, implementation, and application
- The GAIA Project: evaluation of GPU-based programming environments for knowledge discovery
- Extended-precision floating-point numbers for GPU computation[21]
- A new range-reduction algorithm
- Some functions computable with a fused-mac, arith

## Fast Implementation of DGEMM on Fermi GPU
- Self-adapting linear algebra algorithms and software
- Anatomy of high-performance matrix multiplication
- A note on auto-tuning gemm for gpus


## Efficient Sparse Matrix-Vector Multiplication on CUDA[*]
- Solving dense linear systems on graphics processors
- Prefix sums and their applications
- Segmented operations for sparse matrix computation on vector multiprocessors
- Concurrent number cruncher - a GPU implementation of a general sparse linear solver
- Vectorized sparse matrix multiply for compressed row storage format
- Toward the optimal preconditioned eigensolver: Locally optimal block preconditioned conjugate gradient method
- Basic Linear Algebra Subprograms for Fortran Usage
- Approximation algorithms for scheduling unrelated parallel machines
- Scalable parallel programming with CUDA
- Iterative Methods for Sparse Linear Systems
- Optimization of sparse matrix-
- vector multiplication on emerging multicore platforms


## Optimization techniques for sparse matrix vector multiplication on GPUs 
- The landscape of parallel computing research: A view from Berkeley
- Fast sparse matrix–vector multiplication on GPUs for graph applications
- An efficient two-dimensional blocking strategy for sparse matrix–vector multiplication on GPUs
- Warps and atomics: Beyond barrier synchronization in the verification of GPU kernels
- Optimizing Sparse Matrix-Vector Multiplication on GPUs
- Implementing sparse matrix–vector multiplication on throughput-oriented processors
- Matrix market: A web resource for test matrix collections
- Model-driven autotuning of sparse matrix–vector multiply on GPUs
- SpMV: A memory-bound application on the GPU Stuck between a Rock and a Hard Place
- Optimization of sparse matrix–vector multiplication with variant CSR on GPUs
- High-performance graph algorithms from parallel sparse matrices
- Efficient sparse matrix–vector multiplication on GPUs using the CSR storage format
- Adaptive row-grouped CSR format for storing of sparse matrices on GPU
- Compressed multirow storage format for sparse matrices on graphics processing units
- A unified sparse matrix data format for modern processors with wide SIMD units
- Evaluation criteria for sparse matrix storage formats
- AdELL: An adaptive warp-balancing ELL format for efficient sparse matrix–vector multiplication on GPUs
- CoAdELL: Adaptivity and compression for improving sparse matrix–vector multiplication on GPUs
- GPU-based steady-state solution of the chemical master equation
- Automatically tuning sparse matrix–vector multiplication for GPU architectures
- New row-grouped CSR format for storing the sparse matrices on GPU with implementation in CUDA
- Optimization of sparse matrix–vector multiplication using reordering techniques on GPUs
- Iterative Methods for Sparse Linear Systems
- Accelerating sparse matrix–vector multiplication on GPUs Using bit-representation-optimized schemes
- A new approach for sparse matrix vector product on NVIDIA GPUs
- Improving the performance of the sparse matrix vector product with GPUs
- Roofline: An insightful visual performance model for multicore architectures
- Sparse matrix–vector multiplication optimizations based on matrix bandwidth reduction using NVIDIA CUDA
- yaSpVM: Yet another SpMV framework on GPUs


## 
- Optimizing sparse matrix-vector multiplication on gpus
- Implementing sparse matrix-vector multiplication on throughput-oriented processors
- Model-driven autotuning of sparse matrix-vector multiply on GPUs
- Acceleration of conjugate gradient method for circuit simulation using CUDA
- Implement-
- ing Blocked Sparse Matrix-Vector Multiplication on NVIDIA GPUs
- Automatically tuning sparse matrix-vector multiplication for GPU Architectures
- Designing efficient sorting algorithms for manycore GPUs
- Efficient Breadth-First Search on the Cell/BE Processor
- Accelerating Large Graph Al-gorithms on the GPU Using CUDA
- Improving the Performance of the Sparse Matrix Vector Product with GPUs
- Optimization of sparse matrix-vector multiplication on emerging multicore platforms
- Fast
- Sparse Matrix-Vector Multiplication on GPUs: Implications for Graph Mining
- Optimization of linked list prefix computations on multithreaded GPUs using CUDA
-

くわのさん
高橋先生の備品番号のありますか
備品シールの番号

いちばん（自分にとって）効率のよい方法とは
一辺倒になりすぎるのではなく、中間的な位置でつねに場合によって考えるスタンスでいる。
